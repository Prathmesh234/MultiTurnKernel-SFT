[project]
name = "kernelbench-triton"
version = "0.1.0"
description = "Triton kernel benchmarking and trace generation for RL training"
readme = "README.md"
requires-python = ">=3.10,<3.13"
dependencies = [
    "datasets>=2.14.0",
    "openai>=1.0.0",
    "modal>=0.63.0",
    "tqdm>=4.65.0",
    "aiohttp>=3.8.0",
    "numpy>=1.24.0",
    "pandas>=2.0.0",
    "openai-harmony>=0.0.8",
]

[project.optional-dependencies]
dev = [
    "pytest>=7.0.0",
    "ruff>=0.1.0",
]
gpu = [
    "triton>=3.0.0",
]
# Note: torch and vllm are installed separately via run_gpt_oss.sh script
# because they require specific CUDA index URLs

[dependency-groups]
dev = [
    "pytest>=7.0.0",
    "ruff>=0.1.0",
]

[tool.ruff]
line-length = 100
target-version = "py310"
